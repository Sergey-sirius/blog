
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Analyzing-ratings-data-in-a-Bayesian-Framework">Analyzing ratings data in a Bayesian Framework<a class="anchor-link" href="#Analyzing-ratings-data-in-a-Bayesian-Framework">&#182;</a></h1><p>The Problem: Suppose you go to Amazon in search of a book on Bayesian statistics and enter "Bayesian statistics" as your search query. You obviously want the best book, so you go and sort by average rating. The result is a bunch of books with relatively few ratings, all of which are very high.</p>
<p>
<div class="row">
<div class="col-md-12">
<img src="/embed_html/search_results.png" alt="">
</div>
</div>
</p>
<p>Now I'm sure that these are all great books, but the issue is that there aren't enough ratings to give a good estimate of what the <em>true</em> average rating is for each of these books.</p>
<p>The fix: We can use Bayesian data analysis to incorporate the lack of information and uncertainty into our estimate of the true mean.</p>
<p>The inspiration: I saw Erik Bernhardsson's post <a href="https://erikbern.com/2015/12/05/more-mcmc-analyzing-a-small-dataset-with-1-5-ratings/"><em>Analyzing a small dataset with 1-5 ratings</em></a> and thought I would expand on it and show another example.
Note that the code appears to be missing from his post.</p>
<p>But let's take a step back, introduce Bayesian inference, do a simple example, and then apply what we've learned to the problem at hand.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="A-quick-introduction-to-Bayesian-inference">A quick introduction to Bayesian inference<a class="anchor-link" href="#A-quick-introduction-to-Bayesian-inference">&#182;</a></h2><p>Note: This really quick introduction to Bayesian data analysis will roughly follow and occasionally borrow material from <a href="http://www.stat.columbia.edu/~gelman/book/">Bayesian Data Analysis</a> by Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin.
Any unattributed quotes are from this book.</p>
<h3 id="What-is-Bayesian-inference?">What is Bayesian inference?<a class="anchor-link" href="#What-is-Bayesian-inference?">&#182;</a></h3><p>Well first, what is statistical inference?
Statistical inference is the process of determining the parameters of an underlying probability distribution based on some data.
So, for example, given sex data on a bunch of births, can we estimate the true probability of a male or female birth?</p>
<p>Bayesian inerence, then, is using <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes' theorem</a> to perform statistical inference.
From Gelman, et al:</p>
<blockquote><p>Bayesian inference is the process of fitting a probability model to a set of data and summarizing the result by a probability distribution on the parameters of the model and on unobserved quantities such as predictions for new observations.</p>
</blockquote>
<h3 id="Traditional-and-Bayesian-inference-example">Traditional and Bayesian inference example<a class="anchor-link" href="#Traditional-and-Bayesian-inference-example">&#182;</a></h3><h4 id="Traditional-Inference-method">Traditional Inference method<a class="anchor-link" href="#Traditional-Inference-method">&#182;</a></h4><p>Let's continue with the example of male and female births from above.
In the 18th century Laplace attempted to estimate the female birth rate in Paris.
He found that 241,945 girls and 251,527 boys were born in Paris between 1745 and 1770.</p>
<p>Using traditional inference methods first, let's estimate what the true proportion of female births in Paris is.
We assume that the birth data is drawn from a <a href="https://en.wikipedia.org/wiki/Binomial_distribution">binomial distribution</a>, which is a "discrete probability distribution of the number of successes in a sequence of $n$ independent yes/no experiments, each of which yields success with probability $p$."</p>
<p>The estimate for the proportion is just the ratio of female briths to total births.</p>
$$\hat{p} = \frac{\text{# girl births}}{\text{# total births}} = \frac{241,945}{241,945+251,527} \approx 0.490$$<p>How certain are we of this estimate though?
How wide is the range of values that the true number of births could take on?
To answer these questions we need to compute a confidence interval and perform a statistical hypothesis test.</p>
<p>Let's start with a hypothesis test for the true parameter $p$ to see if it is statistically different from $\frac{1}{2}$.</p>
<p>To perform a hypothesis test for a binomial proportion we first need a null hypothesis $H_0$.
Our null hypothesis is of course that the true birth rate for females is the same as that of males, i.e. $H_0: \hat{p}=p_0 = 0.5$.
Our alternative hypothesis is that the birth rates are not equal, i.e. $H_A: \hat{p} \ne p_0$.</p>
<p>The test statistic that we need is a one-proportion z-test:</p>
$$
z = \frac{\hat{p} - p_0}{\sqrt{p_0(1-p_0)}}\sqrt{n}.
$$<p>Plugging in:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">math</span> <span class="k">import</span> <span class="n">sqrt</span>

<span class="k">def</span> <span class="nf">one_prop_z</span><span class="p">(</span><span class="n">p_hat</span><span class="p">,</span> <span class="n">p_0</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">p_hat</span> <span class="o">-</span> <span class="n">p_0</span><span class="p">)</span><span class="o">/</span><span class="n">sqrt</span><span class="p">(</span><span class="n">p_0</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p_0</span><span class="p">))</span><span class="o">*</span><span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">z</span>

<span class="n">female_births</span> <span class="o">=</span> <span class="mi">241945</span>
<span class="n">male_births</span> <span class="o">=</span> <span class="mi">251527</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">female_births</span> <span class="o">+</span> <span class="n">male_births</span>
<span class="n">p_hat</span> <span class="o">=</span> <span class="n">female_births</span><span class="o">/</span><span class="n">n</span>

<span class="nb">print</span><span class="p">(</span><span class="n">one_prop_z</span><span class="p">(</span><span class="n">p_hat</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>-13.640330988151018
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since our computed z-score is -13.6 &lt; -1.96, we can reject the null hypothesis and conclude that the true proportion is not $0.5$.</p>
<p>Now let's compute a <a href="https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval">binomial proportion confidence interval</a>.
We have a lot of data so we don't need to compute the Wilson score interval and can use the normal approximation, but let's do both.</p>
<p>Aside: For those of you familiar with reddit, their "best" ranking uses the lower bound of the Wilson score confidence interval of upvotes and downvotes to get a pessimistic estimate of the true upvote and downvote ratio of the link. This keeps links with just one upvote from being ranked highly, even though the score is basically perfect. You can see the code <a href="https://github.com/reddit/reddit/blob/master/r2/r2/lib/db/_sorts.pyx">here</a>. The "hot" ranking is pretty neat too.</p>
<p>The Wilson score interval is given by
$$
\frac{1}{1 + \frac{1}{n} z^2}
  \left[
    \hat{p} + \frac{1}{2n} z^2 \pm
    z \sqrt{
      \frac{1}{n}\hat{p} \left(1 - \hat{p}\right) +
      \frac{1}{4n^2}z^2
    } 
   \right]
$$
where $z$ is the z-score for the $1-\frac{1}{2}\alpha$ quantile of the standard normal distribution. In our case, we'll compute a 95% conifdence interval, so $\alpha = 0.05$ and $z=1.96$.</p>
<p>The normal approximation interval is 
$$
\hat{p} \pm z\sqrt{\frac{1}{n}\hat{p}(1-\hat{p})}.
$$</p>
<p>Let's compute them.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">math</span> <span class="k">import</span> <span class="n">sqrt</span>

<span class="k">def</span> <span class="nf">wilson_score_interval</span><span class="p">(</span><span class="n">p_hat</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
    <span class="n">pm</span> <span class="o">=</span> <span class="n">z</span><span class="o">*</span><span class="n">sqrt</span><span class="p">(</span><span class="n">p_hat</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p_hat</span><span class="p">)</span><span class="o">/</span><span class="n">n</span> <span class="o">+</span> <span class="n">z</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mi">4</span><span class="o">*</span><span class="n">n</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
    <span class="n">inner</span> <span class="o">=</span> <span class="n">p_hat</span> <span class="o">+</span> <span class="n">z</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">n</span><span class="p">)</span>
    <span class="n">outer</span> <span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">z</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">n</span><span class="p">))</span>
    <span class="n">lower_bound</span> <span class="o">=</span> <span class="n">outer</span><span class="o">*</span><span class="p">(</span><span class="n">inner</span> <span class="o">-</span> <span class="n">pm</span><span class="p">)</span>
    <span class="n">upper_bound</span> <span class="o">=</span> <span class="n">outer</span><span class="o">*</span><span class="p">(</span><span class="n">inner</span> <span class="o">+</span> <span class="n">pm</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">lower_bound</span><span class="p">,</span> <span class="n">upper_bound</span>

<span class="k">def</span> <span class="nf">normal_approx_interval</span><span class="p">(</span><span class="n">p_hat</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
    <span class="n">right</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">p_hat</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p_hat</span><span class="p">)</span><span class="o">/</span><span class="n">n</span><span class="p">)</span>
    <span class="n">lower</span> <span class="o">=</span> <span class="n">p_hat</span> <span class="o">-</span> <span class="n">right</span>
    <span class="n">upper</span> <span class="o">=</span> <span class="n">p_hat</span> <span class="o">+</span> <span class="n">right</span>
    <span class="k">return</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span>

<span class="n">female_births</span> <span class="o">=</span> <span class="mi">241945</span>
<span class="n">male_births</span> <span class="o">=</span> <span class="mi">251527</span>
<span class="n">z</span> <span class="o">=</span> <span class="mf">1.96</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">female_births</span> <span class="o">+</span> <span class="n">male_births</span>
<span class="n">p_hat</span> <span class="o">=</span> <span class="n">female_births</span><span class="o">/</span><span class="n">n</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Wilson score interval: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">wilson_score_interval</span><span class="p">(</span><span class="n">p_hat</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">z</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Normal approx interval: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">normal_approx_interval</span><span class="p">(</span><span class="n">p_hat</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">z</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Wilson score interval: (0.4888965202876094, 0.4916861157965965)
Normal approx interval: (0.4895796081852655, 0.49100287673789117)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We see that the normal approximation interval and the Wilson score interval are very close, and that neither contain $0.5$. This confirms that the true proportion is very likely not 0.5, but is in fact lower.</p>
<h4 id="Bayesian-Inference-method">Bayesian Inference method<a class="anchor-link" href="#Bayesian-Inference-method">&#182;</a></h4><p>Now we are going to do estimate the true proportion of male and female births using Bayesian inference.
Bayes' rule tells us that we can compute the distribution of the paramater conditional on the data in the following way:</p>
<p>Let $\theta$ be the parameter (or parameters) of interest and let $y$ be the data that's been collected. 
We assume that the data comes from a distribution condiitional on $\theta$, i.e. $p(y|\theta)$.
This is called the <em>likelihood</em> or the <em>sampling distribution</em>.
We assume further that the parameter is a random variable from another distribution $p(\theta)$ called the <em>prior</em>.
The prior represents our prior (before looking at our data) beliefs about the parameters. 
Note that while we used $p$ for both the likelihood and the prior, that $p$ is in fact two different distributions distinguished by the parameters.
It is an abuse of notation for convenience and the different parameters of each distribution indicate to the reader that they are different.
Using $p(y|\theta)$ and $p(\theta)$ we have
$$
p(\theta,y) = p(y,\theta) = p(y|\theta)p(\theta)
$$
If we have also the marginal distribtution of $y$, 
$$p(y) = \int p(y,\theta)d\theta = \int p(y|\theta)p(\theta)d\theta.
$$
then we can compute the distribution for $\theta$ conditional upon $y$ simply by conditioning the joint $p(\theta,y)$ on $y$.
Concretely,
$$
p(\theta|y) = \frac{p(y|\theta)p(\theta)}{p(y)},
$$
which is precisely the distribution of the parameter conditional upon the data, called the <em>posterior distribution</em> that we were seeking.</p>
<p>However, since we are looking for $p(\theta|y)$ as a function of $\theta$, and since the marginal distribution of $y$ does not depend on $\theta$, we also have
$$
p(\theta|y) \propto p(y|\theta)p(\theta).
$$
Essentially, $p(y)$ is constant so we can compute an unnormalized density function to avoid having to marginalize.
This makes our lives easier and only puts us off the true posterior distribution by a constant factor.</p>
<p>Back to trying to compute the true population birth proportion.
Just as before, we assume that the data is sampled from a binomial distribution with unknown proportion parameter $p$, which we are going to relabel as $q$ since we are going to use $p$ for all of our pdfs.
Let $g$ be the number of girls born and $n$ be the total number of births. Our likeihood pdf is then $p(g|q,n) = {n \choose g} q^g(1-q)^{n-g}$.</p>
<p>Now we need a prior which means we have to make a choice.
How do we choose a prior? 
This <a href="http://stats.stackexchange.com/questions/78606/how-to-choose-prior-in-bayesian-parameter-estimation">stats.se answer</a> gives a good overview. If you have access to <em>Introduction to Bayesian Statistics</em> by William M. Bolstad, there is an excellent discussion on choosing a prior for a binomial likelihood in section 8.3.</p>
<p>We are actually going to do the analysis with two different choices of prior, a uniform (Laplace's choice) and a beta distribution (<a href="https://en.wikipedia.org/wiki/Conjugate_prior">conjugate prior</a>).</p>
<p>First the uniform prior.</p>
<ul>
<li>Likelihood: $p(g|q,n) = {n \choose g} q^g(1-q)^{n-g}$</li>
<li>Prior: $p(q|n) = 1$</li>
</ul>
<p>This gives:</p>
<ul>
<li>Posterior: $p(q|g,n) \propto p(g|q,n)p(q|n) = {n \choose g} q^g(1-q)^{n-g} \times 1 = {n \choose g} q^g(1-q)^{n-g}$</li>
</ul>
<p>Now, even without know the constant of proportionality, we can recognize $p(q|g,n)$ as a <a href="https://en.wikipedia.org/wiki/Beta_distribution">beta distribution</a>!
That means we actually have the full, normalized distribution without having to compute marginal of $g$.</p>
<ul>
<li>Posterior: $p(q|g,n) = \frac{p(g|q,n)p(q|n)}{p(g|n)} =  \frac{q^g(1-q)^{n-g}}{B(g+1,n-g+1)}$</li>
</ul>
<p>where $B$ is the <a href="https://en.wikipedia.org/wiki/Beta_function">beta function</a>.</p>
<p>In other words, $q|g,n \sim Beta(g+1,n-g+1)$.</p>
<p>Using this we can get compute a credible interval, which is the Bayesian analog to a confidence interval.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">beta</span>

<span class="nb">print</span><span class="p">(</span><span class="n">beta</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.025</span><span class="p">,</span> <span class="mi">241945</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="mi">251527</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">beta</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.975</span><span class="p">,</span> <span class="mi">241945</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="mi">251527</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>0.48889654636
0.491686091798
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You'll notice that this is pretty much exactly what we got from the frequentist confidence interval.
The key difference for us here is the interpretation of what this interval means.
<a href="http://jakevdp.github.io/blog/2014/06/12/frequentism-and-bayesianism-3-confidence-credibility/">Jake VanderPlas says it better than I ever could</a>:</p>
<blockquote><p>The above derivation is one reason why the frequentist confidence interval and the Bayesian credible region are so often confused. In many simple problems, they correspond exactly. But we must be clear that even though the two are numerically equivalent, their interpretation is very different.</p>
<p>Recall that in Bayesianism, the probability distributions reflect our degree of belief. So when we computed the credible region above, it's equivalent to saying</p>
<blockquote><p>"Given our observed data, there is a 95% probability that the true value of μ falls within CRμ" - Bayesians</p>
</blockquote>
<p>In frequentism, on the other hand, μμ is considered a fixed value and the data (and all quantities derived from the data, including the bounds of the confidence interval) are random variables. So the frequentist confidence interval is equivalent to saying</p>
<blockquote><p>"There is a 95% probability that when I compute CIμ from data of this sort, the true mean will fall within CIμ." - Frequentists</p>
</blockquote>
<p>Note the difference: the Bayesian solution is a statement of probability about the parameter value given fixed bounds. The frequentist solution is a probability about the bounds given a fixed parameter value. This follows directly from the philosophical definitions of probability that the two approaches are based on.</p>
</blockquote>
<p>Now for the Beta prior. In this case we are going to use Beta(1/2,1/2) which is the <a href="https://en.wikipedia.org/wiki/Jeffreys_prior">Jeffreys Prior</a>. Even though this type of prior appears in <a href="http://www.stats.org.uk/priors/noninformative/YangBerger1998.pdf">Yang and Berger's "A Catalog of Noninformative Priors" (pdf link)</a> it is not really a noninformative prior.</p>
<p>As Bolstad says:</p>
<blockquote><p>If we think of the parameter as an index of all possible densities the observation could come from, then any continuous function of the parameter would give an equally valid index. Jeffreys' method gives a pries that is invariant under any continuous transformation of the parameter. That means that Jeffreys' prior is objective in the sense that it does not depend on the particular parameterization we used. <strong>However, for most parameterizations, the Jeffreys' prior gives more weight to some values than to others so it is usually informative, not noninformative.</strong></p>
</blockquote>
<ul>
<li>Likelihood: $p(g|q,n) = {n \choose g} q^g(1-q)^{n-g}$</li>
<li>Prior: $p(q|n) = \frac{q^{-1/2}(1-q)^{-1/2}}{B(1/2,1/2)}$</li>
</ul>
<p>This gives:</p>
<ul>
<li>Posterior: $p(q|g,n) \propto p(g|q,n)p(q|n) = {n \choose g} q^g(1-q)^{n-g} \times \frac{q^{-1/2}(1-q)^{-1/2}}{B(1/2,1/2)} = {n \choose g} \frac{q^g(q-1/2)^{n-g-1/2}}{B(1/2,1/2)} = Beta(g+1/2, n-g+1/2)$</li>
</ul>
<p>Actually computing it, we get:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">beta</span>

<span class="nb">print</span><span class="p">(</span><span class="n">beta</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.025</span><span class="p">,</span> <span class="mi">241945</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span><span class="mi">251527</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">beta</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.975</span><span class="p">,</span> <span class="mi">241945</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span><span class="mi">251527</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>0.488896525274
0.491686073536
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is different, but not really.
Neither of the priors make a huge difference because we have a preponderance of data.</p>
<p>What if we don't want to do a bunch of algebra and comparing our distribution to known ones?
We can simulate random draws from the posterior distribution without knowing what it is explicitly.
This is useful for when our likelihood and our prior aren't so simple and compitable, and the posterior is consequently an ugly mess that isn't a known or well studied probability distribution.
Using these draws from the posterior, we can get a Bayesion credibility interval by simply computing the middle 95% of the data.</p>
<p>The following code shows how to do this.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">pymc</span> <span class="k">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">female_births</span> <span class="o">=</span> <span class="mi">241945</span>
<span class="n">male_births</span> <span class="o">=</span> <span class="mi">251527</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">female_births</span> <span class="o">+</span> <span class="n">male_births</span>

<span class="n">prior</span> <span class="o">=</span> <span class="n">Uniform</span><span class="p">(</span><span class="s1">&#39;prior&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
<span class="n">likelihood</span> <span class="o">=</span> <span class="n">Binomial</span><span class="p">(</span><span class="s1">&#39;likelihood&#39;</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">female_births</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">([</span><span class="n">prior</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">])</span>
<span class="n">prior</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="c1">#print(model.logp)</span>

<span class="n">mc</span> <span class="o">=</span> <span class="n">MCMC</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">mc</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">iter</span><span class="o">=</span><span class="mi">500000</span><span class="p">,</span><span class="n">burn</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">prior</span><span class="o">.</span><span class="n">trace</span><span class="p">())</span>
<span class="n">sns</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(</span><span class="si">{}</span><span class="s2">, </span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">prior</span><span class="o">.</span><span class="n">trace</span><span class="p">(),</span> <span class="mf">2.5</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">prior</span><span class="o">.</span><span class="n">trace</span><span class="p">(),</span> <span class="mf">97.5</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre> [-----------------100%-----------------] 500000 of 500000 complete in 21.5 sec</pre>
</div>
</div>

<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/keith/.virtualenvs/notebooks/lib/python3.5/site-packages/statsmodels/nonparametric/kdetools.py:20: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  y = X[:m/2+1] + np.r_[0,X[m/2+1:],0]*1j
</pre>
</div>
</div>

<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYEAAAECCAYAAAAYfWtSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz
AAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xt0m/d93/E3HtyvvIKgeNHFlvWzZEdO7MaJvcR207hL
urRud9bTtafbadc46+Zm7Xa6s9Y9u3Srm27d8bak6y1x42W9pK2bdE0d13EjVZac2JEs27r/RIqi
RFG8XwAQxIUAnv3xADLtSCJIPSQeAN/XOTwmHzwAv6YAfPD8ri7TNBFCCNGajHoXIIQQon4kBIQQ
ooVJCAghRAuTEBBCiBYmISCEEC1MQkAIIVqYp5aTlFK/BPxQ5fzfAl4BngXKwCmt9ROV8x4HPgWs
AE9prZ/fhJqFEELYZM0rAaXUw8ADWusHge8FbgeeBp7UWj8MGEqpx5RSCeDTwAPAx4DPKKW8m1e6
EEKIW1VLc9DfB04ppf4S+KvK171a68OV218AHgXuB45orYta6xQwBOzfhJqFEELYpJbmoG5gO/AJ
4DasEFgdHmkgBkSB5KrjS0CbPWUKIYTYDLWEwBxwVmtdBM4rpXLAwKrbo8AikMIKg3cfF0II4VC1
hMAR4F8B/0Mp1QeEgW8qpR7WWh8CPg4cAI4CTymlfEAQuBM4dbMHNk3TdLlct1K/EEK0ItveOF21
LCCnlPoN4COVX/zLwCjwBcALnAUe11qbSqmfAf555byntNZ/ucZDmzMz6Y1Xv0Xi8ShSp30aoc5G
qBGkTrs1UJ22hUBNQ0S11r90ncOPXOe8Z4BnbrEmIYQQW0QmiwkhRAuTEBBCiBYmISCEEC1MQkAI
IVqYhIAQQrQwCQEhhGhhEgJCCNHCJASEEKKFSQgIIUQLkxAQQogWJiEghBAtrKa1g4QQ71QumxSK
JVy48Pvc9S5HiA2TEBBinb768gh//e1RTBPchosffeR2vv/+7fUuS4gNkeYgIdbhO2en+Nq3RomF
vOzb0UY44ObLB4Z59vlTLCwuUsvS7EI4iVwJCHETpmmSTqcAmFrI8cWvn8XncXHPdj893WF29vg5
cnqel09O8+0z0+wdjDKYiBL0u9kzEKOnPUA0GkM2TxJOJSEgxE2k0yleem2YQDDEwbdmya+UuavP
RSzsJRSOEgrDDzwQ482hWUYnkpwYTXNi1NqUxON28eG9ER57aA+xmGy3LZxJQkCINQRDYTIrHubT
Kwz0RNjR+85WVJ/Xzf37EuzqKpEpuPAGYswsZjlxYY5TY3l+UJqIhINJn4AQNTh3aQGAvTvab3iO
y+UiFnTTHw9zz+4uBnoizCQLHD4xvVVlCrFuEgJCrCFXKHFpMk1b2EdvZ6im+7hcLh64K4HPY/DX
r44zPpvZ5CqF2BgJASHWMDK5TNkEtaN9XR28Qb+H++5oY6Vk8vt/dZqVYnkTqxRiYyQEhLiJUtlk
ZCKD121we9/6O3f7u4M8sK+bsekl/uLQhU2oUIhbIyEgxE2cu5wiVyhzW38Mr2f9LxfTNPno/jbi
7X6+cXSMo6fHSKWSMp9AOIaEgBA38Z1zswDc3r+xIZ7Z5QzfPnmF/TujuFzwxRcv8Pwr56/NPRCi
3iQEhLiB9HKBU6NJYiEPXTH/hh8nEAzR39vF++7oJlcoc/rKilwJCMeQEBDiBl49PUWpbLIzEbJl
xu9duzrp7QxxdS7H8aEFGyoU4tZJCAhxA0dOTmAYsL0naMvjuVwuHrg7AcDBNyflakA4goSAENdx
8WqSsekl9u1oI2DjUtHRkI/+rgBXZrMMXUna9rhCbJSEgBDX8fIb4wB8z54u2x97d38YgL89Nmb7
YwuxXhICQryLaZocfnMcv9fNvu32L/zWHfPR3x3k+PlZ5pI52x9fiPWoaQE5pdTrQPXa9SLw68Cz
QBk4pbV+onLe48CngBXgKa3183YXLMRmqS4bfXkqw9T8Mvfe0UE+twQ2N927XC4e2t/Dnxy4xIE3
rvCjj+y29xcIsQ5rXgkopfwAWuuPVL5+BngaeFJr/TBgKKUeU0olgE8DDwAfAz6jlPJuYu1C2Kq6
bPTXXrWaaQJeOHhshFwua/vvund3J+GAh1dOTlIsyXISon5quRK4BwgrpV4E3MCvAPdqrQ9Xbn8B
+H6sq4IjWusikFJKDQH7gdftL1uIzREIhhifm8HnMdg10M3CbMn232GaJrnsEvfd0cnLJ6d59eQY
+2+zVieVDWjEVqulT2AZ+E2t9d8H/gXwR8DqZ2kaiAFR3m4yAlgCZCcN0VDm0iss54rs6m/DbWxO
l1l2OcOh45fxea12phe+c4UjJyd46bVhmUkstlwtz/LzWG/8aK2HgDkgser2KLAIpLDC4N3HhWgY
V2aspp/dAzfeN8AOgWCIvp5OumIBJufz4A4QDIU39XcKcT21NAf9NFazzhNKqT6sN/pvKKUe1lof
Aj4OHACOAk8ppXxAELgTOLXWg8fj0Y3WvqWkTns5sU6Pp8T4XA6/181gIoLbMMhmfBiGl2gkcO28
6x270fG1jt29u5tDx68wNrPM3sEg3d1R2trW97dx4t/yeqROZ6olBJ4B/kAp9TLWOImfwroa+EKl
4/cs8JzW2lRKfRY4gtVc9KTWurDWg8/MpDda+5aJx6NSp42cWufxsxNk8yV2D1hNQemlHJlMAcMo
4Q++PZTzesdudHytY9s6ArgNF2cvzjHQ0c3sbJpCofZmKKf+Ld9N6rSXnUG1ZghUOnr/6XVueuQ6
5z6DFRpCNJw3hq31fHb2bt0nQZ/XzUA8zKWpJVLLxS37vUJUyWQxIYBSucxbIwv4vUbNW0jaZUcl
dKr9EUJsJQkBIYBzlxdZyhbp7wpgGFs7RLM/HsFtuLgyK7OHxdaTEBACOHp2CoDBuD0rhq6H12PQ
Hw+TzhaZnJerAbG1JAREyyuWyryuZ4iFvHS3+epSw/aE1ST05gXZZ0BsLQkB0fLOjC6QyRV57+0d
dZutO9ATxnBJCIitJyEgWl61Keh9uzvqVoPP4ybR4WdyPsfMojQJia0jISBa2kqxzPGhWTpjfnb0
1nfGbm+HNaHs1MhcXesQrUVCQLQk0zRJpZIcPT1GNl/knl3tZJbSti8bvR69ndZm9idH5utXhGg5
Ne0nIESzqS4bffKyNand5Spx8NgIoXCMUKQ+ywaEAx562v2cvbTASrGM1yOf0cTmk2eZaFn+QIiJ
hTzhgIf+RCeBYP0XcLtzexv5lRJDV2TtRbE1JAREy5pO5lkpltmeiDpmDf+9262FeE9Kv4DYIhIC
omVdrczQHUxE6lzJ23b3RfF5DOkXEFtGQkC0pLJpcnXeWja6p33rZwlfT3XHsd19Ea7OZrg0PkMq
lcQ069hbLZqehIBoSZenMuQKZWuS1havFXQj1R3HvJXhGl9/bUx2GxObTkJAtKSTF62O1+pyDU4R
CIYY7LUmrc1nyrLbmNh0EgKiJZ28uIjbcLGta2uXja5FR9SPz2swJYvJiS0gISBazvTCMtOLeRId
fjxu570EXC4XiY4QS9kVMjnZaEZsLue9AoTYZNWRN70d/jpXcmOJTquzeja55g6tQtwSCQHRck5c
sMbgOzkEqrubzSTzda5ENDsJAdFSCislzl1eoLczQCjg3FVTqv0CM3IlIDaZhIBoKXpskZVimb3b
2+pdyk1V+wUyuRLzabkaEJtHQkC0lJOVpqDq8gxOVu0XGB5fqnMloplJCIiWcmJkDr/PzW3bnLNU
xI30dFj9AqOTEgJi80gIiJYxu5hleiHLvh0djhwa+m6dUT9uw8XFyUy9SxFNzPmvBCFsMjyeBGDP
YHudK6mNYbjoiHqZnM+yLPMFxCaREBBNrbqDWCqV5OzoDAC97W5rPZ4GWJetK+bDBEYmkvUuRTQp
CQHR1Ko7iB05OcHJi4sYLrg8leLgsRFyOecvy9Ad8wEwfEVCQGwOCQHR9IKhMF5/mGRmhc5YgGg0
5ohdxGrRGbVC4MK4hIDYHBICoiXMpXKYJsQdsndArfxeg572ABeupiiXG6D9SjQcCQHREmYWraaf
eEdjhQDArt4wuUKJ8VkZJSTsV9O8eaVUD3AM+ChQAp4FysAprfUTlXMeBz4FrABPaa2f34yChdiI
mUVrK8l4e6DOlazfrt4Ir52bY3g8yWCP8+c3iMay5pWAUsoD/C6wXDn0NPCk1vphwFBKPaaUSgCf
Bh4APgZ8Rinl3aSahVgX0zSZXcwSCngIBxrvabmrMrFNX16ocyWiGdXSHPTfgd8BrgIu4F6t9eHK
bS8AjwL3A0e01kWtdQoYAvZvQr1CrFsmVyJXKDVcf0BVT7uftoiPc5cWZL9hYbubhoBS6qeAaa31
S1gB8O77pIEYEAVWD19YApy9QpdoGXNpayXORmwKMk2TpaU0d/RFSC2voEenZPN5Yau1+gR+Gigr
pR4F7gG+BMRX3R4FFoEUVhi8+/ia4nFn7fF6I1KnvbaqTp+vTDpbAmDHtjaiESsIshkfhuG99vP1
jkUjgZrOu9nxW7//HEf1FH6fNVT04FuT7Orx8EOP7KOtzXrJyb+5vRqlTrvcNAQq7f4AKKUOAD8L
/KZS6iGt9cvAx4EDwFHgKaWUDwgCdwKnailgZia9wdK3TjwelTpttJV1plJpJudyGIaLgNcgvWR1
EGcyBQyjhD+Yu3bu6mPRSID0Um7N81ar9dz1399Nb1cMmOXqXJ4d8QCzs2kKBUP+zW3WSHXaZSND
RH8R+M9KqVcAL/Cc1noK+CxwBPhbrI5j2Q1D1F1+pUQys0JXzFqMrVGFg16iIS9T88syX0DYquat
lbTWH1n14yPXuf0Z4BkbahLCNpenlzFpvEli17OtK8T5sSTzSyv1LkU0EZksJppadS3+5ggBa6mL
6UXZaUzYR0JANLXRylr8zRACicrm89MLEgLCPhICommZpsnoVIaQ3+3oTeVrFfC56WoLMJcukCuU
6l2OaBISAqJpTS9kyeSKdFWWY24G/d1hTBPOX3H+CBbRGCQERNOq7iTWGW28pSJupK/b6hc4d1mW
lhb2kBAQTUuPWfMVu5voSqC7LYDX7eLcWEpmDQtbSAiIpmSaJqcvzhMOuGmPNM+VgGG46OnwM58u
MDm/vPYdhFiDhIBoSpPzyyyk89zRH8PlatxJYtfT2+EH4NTIfJ0rEc1AQkA0pdMXrTfIOwdja5zZ
eBId1tpCJy/O1bkS0QwkBERTqoaAasIQCPnd9HYGOH95kWKpXO9yRIOTEBBNp1gqc25skURniI5o
83QKr3b7tiiFYpkLV2parFeIG5IQEE3DNE1SqSQnh66SL5S4oy9MOp2CJhxEc1tlt7EzF6VfQNwa
CQHRNNLpFC+9Nszfvn4VgHK5xMFjI+Ry2TpXZr9qCJwekX4BcWskBERTCYbCzKSKuFywva+TQDBc
75I2RUfUR1fMz5mL8zJfQNwSCQHRVAorZeaSObrbgvg87nqXs6nuGGwnvSzzBcStkRAQTWUmmccE
+rpD9S5l090x0A7A+THpHBYbJyEgmspUZZnlvq7mbAYCqwM8nU7R125d6Zy5OCObz4sNkxAQTWVq
MY/XY9DVFlj75AaVXc5w6PhlhscX8HkNzlxK8tJrw9ZIKCHWSUJANI3ZZJ5MrkRvZwijgfcTrkUg
GCIcidHXHSGTK4GneUNPbC4JAdE09BXrk/C2FugPqOrpsP5fF9Ky77DYGAkB0TT0mBUCzdwf8G7x
DmvbzEXZfF5skISAaArlssnQeJqQ30001DxLR6+lGgILEgJigyQERFO4OJkimy+R6PA33dLRNxMO
eAn63SwuFepdimhQEgKiKVTX0Em0++tcydbrigXIFsqkl+VqQKyfhIBoCqcvzuMCelowBDpj1sig
K7Myc1isn4SAaHjZfJELV1MM9oTweVvvKV2dEzE2LSEg1q/1XjGi6eixRUplEzXQfBvI1KIzZl39
yJWA2AgJAdHwqv0Be5pwF7FahPwe/F6DsRkJAbF+EgKi4Z0encfvdbOrt3XmB6zmcrloj3hZSBdY
ykrnsFgfz1onKKUM4POAAsrAzwJ54NnKz6e01k9Uzn0c+BSwAjyltX5+c8oWwrKQzjMxt8x7buvC
427dzzQdES9TC3kuTaa5a1dnvcsRDaSWV80PAqbW+kPAvwd+HXgaeFJr/TBgKKUeU0olgE8DDwAf
Az6jlGqdWTtiS1W3knzrvLWL2M5EoGm3kqxFe9h6qY1NL9W5EtFo1gwBrfX/w/p0D7ADWADu1Vof
rhx7AXgUuB84orUuaq1TwBCw3/6ShXh7K8kjJ6cAWFrON+1WkrVoi1RDIF3nSkSjqen6WWtdVkp9
Efgs8MfA6imZaSAGRIHkquNLQJtNdQrxXYKhMHPpIh63i/5E824lWYtIwI3PY8iVgFi3NfsEqrTW
P62U+nfAUSC46qYosAiksMLg3cdvKh6P1lpCXUmd9rrVOn2+Mm7PDMlMgcGeCG2xIPmsD8PwEo28
vaxyNvPdx250/N3HopFATeet5zE34/7RSACDAtsTES5OpGnvCOF14NaarfLcbDS1dAz/E2BAa/0Z
IAeUgGNKqYe11oeAjwMHsMLhKaWUDysk7gROrfX4MzPOv3yNx6NSp43sqDOVSnNp0nqMrrYA6aUc
mUwBwyjhD+aunXe9Yzc6vvpYNGL/Y27G/at1Lmfy9LT5GB43OXFuiu0JZ72RtdJzcyvYGVS1XAk8
BzyrlDpUOf9fAeeAL1Q6fs8Cz2mtTaXUZ4EjWM1FT2qtZVUrsWlmk9bTK9ERXOPM1lDdV3lseslx
ISCca80Q0FpngR+7zk2PXOfcZ4Bnbr0sIdY2k8xjGC6622VXLYD+LisMpV9ArEfrDqwWDW05VySZ
KRJvC+A25GkMsE1CQGyAvHpEQxqdygCQ6GydrSTXEvC56WkPMja9hGm26IQJsW4SAqIhVUMgLk1B
7zDYE2EpuyKbzIiaSQiIhnRp0mry6GqTTuHVBnoigEwaE7WTEBANp2yaXJrOEAm6CficNx6+nrZX
QuDylPQLiNpICIiGMzG3TK5Qpivqq3cpjrNzmzVfc+Rqqs6ViEYhISAazsi4tTpJp4TAd+mI+umK
BRgeT0rnsKiJhIBoOBcqn3I7YxICVaZpkk6nSKWS7EgEWcquMDI2TSolYSBurua1g4RwipGrSbwe
F21hefpWZZczHDo+T3tnF+VyGYAXj42TiJo8+oHdxGKylqO4PrkSEA0lmy8yPpNhe08Yw+Va+w4t
JBAMEQpH6e9pByC5bBIMte7KqqI2EgKioYxOpDCBHQl5c7uRjqgfj9vFzGJr7q0g1kdCQDSU4Up/
wE4JgRsyDBddsQCLSwVWiuV6lyMcTkJANJShMWuLil29kTpX4mzxysqq82mZOSxuTkJANIxy2WR4
PEmiM0Q0JNtX30xPuxUCc6mVOlcinE5CQDSMseklcoUSewZkpMtauishMJ3M17kS4XQSAqJhDF2x
moLuGGivcyXOF/C56WoLMJcqkM2X6l2OcDAJAeFopmmSSiVJpZKcuTgLQF+Hm3Q6BTIH6qYG4mFM
E/QVWUJC3JiEgHC0dDrFS68Nc/jEVc6NJQl4Dc5emuPgsRFyORkCeTP9cavz/MylZJ0rEU4mISAc
LxgKUzYC5AplEl1hwpEYgaAMEV1LV8yP32tw5lKSsiwdIW5AQkA0hOkF61N/ddSLWJvL5aK3089S
tsilSdlfQFyfhIBoCJPzywD0dEoIrMe2DmvntRMX5upciXAqCQHheKZpMj6TIeBz0xn117uchpLo
8GMYcOLCbL1LEQ4lISAcb2FphVyhRH88jEsWjVsXr8fgtt4IFyfSJDMye1h8NwkB4XgT8zkABuKy
VMRG7NthTa47NSJNQuK7SQgIx5uYz2O4oK9bRgStl2ma7Ihb+y68fm7y2pwL2WhGVEkICEdbXCqw
uLRCojOE1yNP1/XKLmc4MzxByO/m9OgiL791lZdeG7Ym2wmBhIBwuLOXrYlO0hS0ccFQmMFElJWS
ydKKRzaaEe8gISAc7fRoJQR65I3rVgzErb/f+MxSnSsRTiMhIBxrpVji/JU00aCHaEg2lb8Vic4Q
bsPFlZlMvUsRDnPTnbqVUh7gD4CdgA94CjgDPAuUgVNa6ycq5z4OfApYAZ7SWj+/aVWLlqDHFikU
y+xIyASxW+VxG/R2hRifybAsq4qKVda6EvhJYFZr/RDwMeC3gKeBJ7XWDwOGUuoxpVQC+DTwQOW8
zyilZNcPcUtOXpgHoLcy61Xcmm2dIQBmZI8BscpNrwSAPwP+vPK9GygC92qtD1eOvQB8P9ZVwRGt
dRFIKaWGgP3A6/aXLFrFiZE5fB6D7jZpCrJDohoCizJpTLztpiGgtV4GUEpFscLgV4D/vuqUNBAD
osDq9WqXANn+SWzY1MIyU/PL3L2rDbchs4Tt0BHz4/MYciUg3mGtKwGUUoPAV4Df0lp/WSn131bd
HAUWgRRWGLz7+Jri8Wjt1daR1Gmvtep89dwMAPfvS1AurRCOvLNJKJvxYRheoquO13qs1nOjkYDt
j7kZ979Rndc7ty8eYXQihcvr3fLnSrM8N5vNWh3DCeBF4Amt9cHK4TeUUg9prV8GPg4cAI4CTyml
fEAQuBM4VUsBMzPOX+I2Ho9KnTa6UZ2maV6bxHT4+CUAOv0FRqcLlMm949xMpoBhlPAHc+s+Vsu5
0UiA9FLO1sfcjPvfrM7r3b+7zc/oBHzn1CTRYIit0ujPTaexM6jWuhL4ZaAd+PdKqf+AtaHfzwOf
q3T8ngWe01qbSqnPAkcAF1bHsTQ8inWp7iLm9QfRV1LEQh6Onx0jFI4RirTWp7PNUu0XGBpP833v
r3MxwhHW6hP4BeAXrnPTI9c59xngGXvKEq0qGAozv+yiXIbBRIxAsFjvkppKR9SP1+PiwlXnf9oV
W0MmiwnHGa9MaOqPyyxhuxkuF/E2P3OpArNJ2aNZSAgIh6luIOP1GLKV5CaJV4bcnh1dqHMlwgkk
BISjLGVLLGVX2NYVwpChoZsi0W7tznZ6dL7OlQgnkBAQjjKxYI1i6ZdVQzdNNOShLezlzOgCZdlX
oOVJCAhHmazsItYvG8hsGpfLhRqMsZRdYWxKVhVtdRICwjHyKyVmkwU6Y35CgTXnMYpboAasuZ3S
JCQkBIRj6LE0ZVOuArbCngFr3sXpixICrU5CQDjG6VFrpZGBHukP2GzRkJftPRGGriTJr8jS0q1M
QkA4Qtk0OXMpid9r0N0mS0dvpuryHLv7whRLZd7U47L5fAuTEBCOMDqRJp0tsq3Tj8slQ0M3U3Y5
w6HjlymWrNnY3zgmm8+3MgkB4QhvDs8CsK1TrgK2QiAYYntfF0G/m/G5HP7A1i0mJ5xFQkA4wlvD
s7gNF4kOf71LaRmGy8XO3hiFlTKTC7LHQKuSEBB1N5fMMTa9xB39UTxueUpupdv6rKGil6eX61yJ
qBd5xYm6O3HBagq6a6dsRrfVOmN+YiEvV+dz5AoySqgVSQiIuntzeA6QEKgHl8vFrr4Y5TKcGKlp
M0DRZCQERF3lCyXOXlpgIB6mMyr9AfWwa5vVJHRUz9W5ElEPEgKiLkzTJJVKcvTMFYqlMnsHo9YQ
RRmqvuViYR/dMR9D42lmF2WPgVYjISDqorqV5IE3JgAoloocPDZCLidvQvWws9caInrk5ESdKxFb
TUJA1E0gGGJyIU/A52agt5NAUNYMqpeB7gB+r8ErJydleekWIyEg6mZhaYVcoUR/PCyzhOvM4zZ4
3+4O5lI5zl2SHcdaiYSAqJurc9beAQOygYwjfODObgAOn5AmoVYiISDqwjRNxmdzuA0XfbJ0tCPs
7A3T1x3m2Llpkksyg7hVSAiIupiYy5LOFhnoieD1yNPQCVwuF9933wClssnBN8brXY7YIvLqE3Xx
xgWr3Xlnb7TOlQh4e3npu7cHCfrdHDx+hfmFBVliugVICIgtZ5ombw4v4DZc9MelKcgJqstLHz03
zWB3gHS2yJ8evChLTLcACQGx5S5eTTGTzLOt0y8LxjlIIBgiFI5y9+0JXMDIZJZAUJaYbnbyChRb
7shbVnvzYDxY50rE9URCXgYTEeZSeebSK/UuR2wyCQGxpUrlMgeOjeH3GvR2yAYyTnXn9g4AhseX
6lyJ2GwSAmJLnRieYy6Z4/2qC7dbJog5VaIzSEfUz/hsjsWlQr3LEZuophBQSn1AKXWw8v3tSqnD
SqlDSqn/veqcx5VSR5VS31JK/YPNKlg0turQwwfvite5EnEzLpeLO3e0YwKvnJqpdzliE60ZAkqp
fwt8Hqiu8/s08KTW+mHAUEo9ppRKAJ8GHgA+BnxGKeXdpJpFg5pezHLq4jx7d3bS1yX9AU63a1sM
n8fgW2dmKKzIhjPNqpYrgWHgR1b9fJ/W+nDl+xeAR4H7gSNa66LWOgUMAfttrVQ0rOqy0d94bQSA
h9/bI8tGNwCP22DXthCZXInXzkzVuxyxSdYMAa31V4HiqkOrG3LTQAyIAslVx5cA2SZKANay0S98
a4gjJ2fweQyWMllZNrpB3L4tjOGCl45dkUljTWojHcPlVd9HgUUghRUG7z4uBADjiyaFYpm9Ozto
a2uXZaMbRMjvZv9tHVyZWeL8mLykm5FnA/c5rpR6SGv9MvBx4ABwFHhKKeUDgsCdwKlaHiweb4xl
A6TOjStTYGg8g89r8P592wAIh30Yhpdo5O1hotlMbcfWc+6t3D8aCTiupvXUaUdNLjPP990b5s0L
C3zz+Bjv2W1d4MdisXUv/+3E5+b1NEqddtlICPwi8PlKx+9Z4DmttamU+ixwBKu56EmtdU3jymZm
0hsoYWvF41Gp8xb85d9dJL9S5p7dXRQKK/h9bjKZAoZRwh/MXTuv1mPrOXej949GAqSXco6qab11
2lHT7Mw8V8ZydES8HDs3yx+9cAajnOfRD+wmFqu9xdepz813a6Q67VJTCGitLwEPVr4fAh65zjnP
AM/YVploCtl8kYNvTuF1u9i7o6Pe5YgNCIbC7Nvl55WTk1yeXWHvgDTlNROZLCY21ddfvUQmV2TP
QASf113WQnQyAAANNUlEQVTvcsQG7dwWJeBzMzSWpFgqr30H0TAkBMSmmU1mefE7Y7SFvdzRL58e
G5nbMNgz2E6hWObytIzqaiYSAmLTfOXQCMVSmU98sF9WC20Cewbbcblg+GpGhos2EXllik1xYTzJ
q2em2NEb5b49nfUuR9ggFPCwIxEltVxkaNz5naeiNhICwjbVmcGLi4v8n785C8BjD/SRWUrL7OAm
sXen1bn/4rEJuRpoEhsZIirEdaXTKV56bZiJJFyZWWZ7T5Crs2lOnZsiFI4RirTW+OtmFG8Psq3T
z4WrS7w5NMv79shCgI1OrgSErQxvkFOX0njdBvfv6yMUjsrs4Cbznl0xDBf82d9dkJFCTUBCQNjq
9GiKQmViWCggF5rNKBby8uBdcabml68tDS4al4SAsM3YdIaRyWXaIj7ulIlhTcs0TT60N0LA5+Yr
hy5waXyGVCopfQQNSkJA2KJsmjx3eAyA+/f2YBiya1izyi5nOHbmKnftiJJfKfO7f32eb7w6ZC0P
LhqOhICwxSsnJ7g0lWGgO8C2LukDaHaBYIh9t/XQ1x1iaiHPVFreShqV/MuJW5ZcyvNnB4bxeQz2
3ybbSLQKl8vFA3f14nUbvDWSlL2IG5SEgNiQ6pyAVCrJs18/TSZX5NH3dRHyyfpArSQc9PI9d8Yp
lky+/HeXpF+gAUkIiA2pzgn48oER3hpZpCvmYzk9J7uFtaDdA20k2v2cu5ziyMmJepcj1klCQGyY
4Q3w5kgKt+Hiw/f0EwxF6l2SqAOXy8V9d7Th9xp8+ZtDTC/KB4FGIiEgNuytCylyhRLvvaObWNhX
73JEHYUCHv7hhwfJ5kv89ldOUlgp1bskUSMJAbEhp0YXuTyTpbstcG09GdG6TNNkX7+PD+7t5vL0
El98/pTMHWgQEgJi3ZZzK/z5ocu4XPDg3b0Y69xrVjSf7HKGQ8cvs63TS3vEy2vn5vi9vzotcwca
gISAWLc/PTBMMrPCvu1R2qP+epcjHCIQDBGNxvjIfYME/W7OXslxfGi+3mWJNUgIiHU5fXGewycm
6O8OogakI1h8t0jQy/fdN4DH7eKPvjnK2VEJAieTEBA1W86t8OwL5zBcLn78e3fK0hDihjpjAR7c
Z20m9LmvnGRkPFnnisSNSAiINZmmyfTsPL/5J8eZS+X46L0J2gJF2ShG3FRPu5+f/OhO8oUS/+nz
32ZGho46koSAWNPU7Dz/9csnuTSVYXtPkGjQxcFjIzIxTNyUaZrsTnj44Q8NspDO85n/eww9Oimj
hhxGQkDcULFU5qVjY/zaH55iYanEzt4oD713kHAkJhvFiDVVRwy5XSXu29PBYmaFp587y5f/9pyM
GnIQ2fVDvEN1TaATI4t87dVxZpN5/F6Du3dGee+ebdIPINYlEAwRCkf54P44Ab+fb52a5NXzGaLR
cX70I1E8bvkcWm8SAuIdTgxd5UsvDrOQKeFywe6+ML3hLO1tHgkAcUtu728jEvRy+K2rvPT6JHps
iU9+Yh8DPTLKrJ4kBAQA86kcf3pgmKPnpgHYnohw7544sbCP2WlZFEzYI9EZ4qPv62Z8Nsvrwyl+
9dmjfOz92/jIe3tpb2/DJRMPt5yEQIsyTZN0OsVKsczLJ6d58egEhWKZgS4/u/sibO/vrneJokkV
C1k6/Hn+3l2dvH5+kedfu8qhtyb5yY/ezv13D9a7vJYjIdCi5uYX+dKLZ7kwWSBbKOPzGHzPHe1E
3SnC/nK9yxNNLhAM0dcdZyDRyRtDM5wfS/K7fz3EC8cm+d739XOfihMOeOtdZkuwNQSUUi7gt4F7
gBzwSa31iJ2/Q2xcNl/kzOg8x8/P8rqeplAs4zZc3LWrk7t3deL3uZmdlgAQW8fvc/PBu3oZ7PIy
PptFj6d59oVz/J+/OcfORJj9u+O857ZudvZGpU9qk9h9JfDDgF9r/aBS6gPA05VjYouZpslcKsfI
1RQXxpOcH1tgbCZDufIe3xHxcFtHiLtvTxAKyAWhqC+/UWCgrchtfQkuTS0zuZDj4mSGi5MZ/t+R
UUJ+N2owxt7tbdy3t4+OaKDeJTcNu1/9HwL+BkBr/ZpS6ntsfnzxLoWVEgtLeRbTeU5fXuTilQWG
xha4NLVEarl47TwX0B7x0tvpZ1tnADM3TzjilQAQjhEIhujsbKe7sx2AiatXmZzPkl7xMbWQ443h
Bd4YXuCPD4yyrTNAvD1Ae8RHR+Ur3hkjGPAQCXppj/hl+GmN7H4HiAGrFwkpKqUMrXXDtjEUS2WS
S3lSmQKmaWICpml90jZNMDHBhDLWDdaxVbdf5z6lskmxVK58mZRKZYrVY8Uy6cwy+ZUS+UKJ/EqZ
XKHESqlMsWhSKJVZKZZZzhVJZlZYzl9/846gz6C/K0BnzIe3vESiM0Y8kbh2++y0bAounM3rcbGj
N0pndw+maZJcKnB+dILpxQLTi3km5nM3vX806KEt4qM94qU97KMt7MXvdRONhPB53fg8bjxuF4ZR
+XK5mE4XSCWzuAxwV44ZLut2l8vaRc0FsOr7az/z9jmA9X3lm+o51f943AZBvzM+gNldRQqIrvq5
oQPANE3+4x98h4m55XqX8l3cLhOfB7qjHvxeFwGfQVvYy3J6ke72ML2Jt0f3zM9mWClkWc6krx3L
ZTMYhucdx250/FaOXe+4QcH2x7T7/gYFljN5R9W03jrrVdPN6ryVx/QZ0BcrMtDuo62jk/xKmWy+
xHK+xOz8Irl8CbfPT6FokiuYLOcKXJ1d4cqM8/oSXC74+X90D/tv76p3KbaHwCvAJ4DnlFIfBE6u
cb4rHo+ucUp9/f6Tj9a7hCa1v94FCCGwPwS+CjyqlHql8vNP2/z4QgghbOSS1fyEEKJ1Sfe5EEK0
MAkBIYRoYRICQgjRwiQEhBCihdVl7SCl1O8Bc1rrJyv3+QKggBLwuNb6vFIqDnweaMeaX/FPtdaX
HFjnnwCJSo07gW9rrX/CgXWqynETOK+1/qQDa9wP/C5QBIaAn9Var9SxTm+lzjuAAvDzWuu3lFK3
A89izRE8pbV+wo4a7a5z1blPA+e01r/vxDqVUu8FPov1757Heq3POLDOfcDvVe4yVHksW+ZBbdK/
+08AP6e1fvBmv9vuK4FrawcBv4y1dtA7KKX+OXD3qkPfD4S11h8C/gvw65Xj/w34Q631I8B/fNd9
HFOn1vrHtdYfAX4EWAB+wYl1Av8J+DWt9UNAQCn1DxxY4xeAf12p8Spg25vrBut8HMhW7vMp4A8q
x58GntRaPwwYSqnHnFinUqpbKfV14AdtrM/2OoH/CTxReR19Ffglh9b5FPBLWusPY33os/Pvamed
KKXeB/yzWn6x3SHwjrWDgHesHaSUegB4P2+nKVip11ZJwjasRAP4e8CAUuol4CeAAw6ts+pXgc9p
racdWmcW6KocjwK2fMK2ucbBymOANfHwIZtq3GiddwEvVO5zHuhTSrUB92mtD1fOeQH4qMPq7FdK
xYAI1geo/2tjfZtR549prasTSz1Yz1Un1vkPtdavKKV8QC/vXCLHMXUqpbqAXwN+vpZfbHcIXHft
IAClVC/WE/Ln4O0lN4AjQBA4h/U/+NnK8Z3AvNb6UWAMez8d2Fknlaarj2A1EdjJzjo/V/n+NNAD
/J0Da7yglPpw5fsfBOzczX49dVa9iTUDnsoM+HilptXnpLGCzEl1dmNdaY1qrY++61wn1jlVOfYg
1tXf/3BonaZSahA4BXQBb2Ef2+rEuqL+N0CGGv7tt3LtoB/F+sN9HdgGBJVSZ4F+4BWt9a8opQaA
A0qp9wBzwNcq9/0aVrI5pc5+4KBS6m6tdQH4R8Afa63tnnln59/zD4EPaa3PKaX+Jdbl5s85oMZr
f0usy9f/pZTyYAVFuw31bbTOc1iX13uVUi8D3wLOA/NU1gusiAKLDq1zM9lap1Lqx7CaQX5Aaz3n
1Dq11mPAHqXUz2CF1U85pM5XKnXurnz9DtYHrb1Kqae11v/mRr/Y7iuBV4AfgGvJdG3tIK3157TW
76+0+/0G1pvml7AuWasJuIAVTAZwGKi2Wz+E9QnWKXUuVup0V37+KJXLMpvZ9fd0AyGsT61gtbfb
9QZr59/yE8BPVK7+uoBv2FTjRuu8HzhQ6aP4c2BSa50Djiulqk1VH8d6rjqtzryNNW1qnUqpn8S6
AnhE2zT4Y5Pq/Cul1O7K3dNYgxqcUudzlToPa63fUzn3HwNnbhYAsAVrBymlfhzrUuoLN7jPbwJf
VEodrtTzy1rrrFLqF4EvKKV+FusNw5YRN3bXWbltD7AZO6jZVeeyUuqTwF8opbJYbfCPO6zGrFLq
PPBNpVQOOAp8yaYaN1qnBv5UKfUkVjt19W/2i8DnK6MzzmK9AJ1YZ9VmrA1jR52frDR5/C/gEvBV
pZQJHNJa/6qD6qz+PX8deFYplQeWAVtG2G1CnesiawcJIUQLk8liQgjRwiQEhBCihUkICCFEC5MQ
EEKIFiYhIIQQLUxCQAghWpiEgBBCtDAJASGEaGH/H/bcb7q+u8DeAAAAAElFTkSuQmCC
"
>
</div>

</div>

<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>(0.48889381223922224, 0.4916867923137298)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Again, we see that the interval is essentially the same. 
This method of simulating draws from the posterior is called <a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">Markov chain Monte Carlo</a> and is very general and very powerful.
However, it may generate slow convergence.
You'll notice we used 500,000 samples from the posterior to generate, but this may be unnecessary and there are <a href="https://pymc-devs.github.io/pymc/modelchecking.html">some diagnostics</a> to discern whether the simulation has converged.</p>
<h2 id="Back-to-our-original-problem-with-1-5-ratings.">Back to our original problem with 1-5 ratings.<a class="anchor-link" href="#Back-to-our-original-problem-with-1-5-ratings.">&#182;</a></h2><p>Obviously the binomial distribution we used just before is not appropriate since it only models yes/no 1/0 type problems.
What we need is a <a href="https://en.wikipedia.org/wiki/Multinomial_distribution">multinomial distribution</a>, which, as that Wikipedia link states, is</p>
<blockquote><p>a generalization of the binomial distribution. For example it models the probability of counts for rolling a k sided die n times. For n independent trials each of which leads to a success for exactly one of k categories, with each category having a given fixed success probability, the multinomial distribution gives the probability of any particular combination of numbers of successes for the various categories.</p>
</blockquote>
<p>This is perfect for the likelihood for our problem.
Let's consider the last book in the picture of the search results above: <em>Statistical Learning with Sparsity</em> by Hastie and Tibshirani (only because of the books in the picture, it has the fewest ratings. I'm sure it's a great book as they are two of the authors of the excellent <em>Elements of Statistical Learning</em>).
We are going to use a <a href="https://en.wikipedia.org/wiki/Dirichlet_distribution">Dirichlet</a> prior, which is conjugate to the multinomial distribution.
As the multinomial distribution is a generalization of the binomial, the Dirichlet is a generalization of the beta distribution.</p>
<p>So we have</p>
<ul>
<li>Likelihood: $p(\mathbf{r}|\mathbf{p}) \sim \text{Multinomial}(\mathbf{r}|\mathbf{p})$ where $\mathbf{r}$ is our data and $\mathbf{p}$ is such that $\sum_{i=1}^k \mathbf{p}_i = 1$</li>
<li>Prior: $p(\mathbf{p}|\mathbf{\alpha}) \sim \text{Dirichlet}(\mathbf{p}|\mathbf{\alpha})$</li>
<li>Prior Hyperparameter: Notice that the prior is dependent on some variable $\mathbf{\alpha}$, which is a prior hyperparameter. In the case of the Dirchlet distribution it is a <a href="https://en.wikipedia.org/wiki/Pseudocount">pseudocount</a>, which means that it represents what we think the distribution of counts might be before hand. We're going to leave it level at all ones. </li>
</ul>
<p>This gives:</p>
<ul>
<li>Posterior: $p(\mathbf{p}|\mathbf{\alpha},\mathbf{r}) \sim \text{Dirichlet}(\mathbf{p}|\mathbf{\alpha} + \mathbf{r})</li>
</ul>
<p>So our posterior for $\mathbf{p}$, the probability parameter that controls how likely each rating is, is distributed Dirichlet with a parameter that's a sum of our assumed prior hyperparameter and our data. We can see now why choosing a flat, low info prior was a good idea – it gives a uniform initial distribution, but doesn't affect the result too much once we get some data.</p>
<p>Anyway, using this, we can compute the posterior means analytically to be $(\frac{1}{9},\frac{1}{9},\frac{1}{9},\frac{1}{9},\frac{5}{9})$, which represents our</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">pymc</span> <span class="k">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="c1"># of success for each possibility</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">4</span><span class="p">]</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">prior</span> <span class="o">=</span> <span class="n">Dirichlet</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;prior&quot;</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">likelihood</span> <span class="o">=</span> <span class="n">Multinomial</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;likelihood&#39;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">([</span><span class="n">prior</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">])</span>

<span class="n">mc</span> <span class="o">=</span> <span class="n">MCMC</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">mc</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">iter</span><span class="o">=</span><span class="mi">500000</span><span class="p">,</span><span class="n">burn</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>



<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(</span><span class="si">{}</span><span class="s2">, </span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">prior</span><span class="o">.</span><span class="n">trace</span><span class="p">(),</span> <span class="mf">0.025</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">prior</span><span class="o">.</span><span class="n">trace</span><span class="p">(),</span> <span class="mf">0.975</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre> [-----------------100%-----------------] 500000 of 500000 complete in 45.7 sec(4.034906069290672e-05, 0.001224735125482726)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">trace</span><span class="p">()</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span> <span class="o">-</span> <span class="n">a</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)])</span><span class="o">.</span><span class="n">T</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="s1">&#39;1&#39;</span><span class="p">,</span> <span class="s1">&#39;2&#39;</span><span class="p">,</span> <span class="s1">&#39;3&#39;</span><span class="p">,</span> <span class="s1">&#39;4&#39;</span><span class="p">,</span> <span class="s1">&#39;5&#39;</span><span class="p">]):</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">a</span><span class="p">[:,</span><span class="n">i</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(</span><span class="si">{}</span><span class="s2">, </span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">a</span><span class="p">[:,</span><span class="n">i</span><span class="p">],</span> <span class="mf">2.5</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">a</span><span class="p">[:,</span><span class="n">i</span><span class="p">],</span> <span class="mf">97.5</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">a</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">means</span><span class="p">)</span>

<span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">means</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Average rating estimate is: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">score</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/keith/.virtualenvs/notebooks/lib/python3.5/site-packages/statsmodels/nonparametric/kdetools.py:20: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  y = X[:m/2+1] + np.r_[0,X[m/2+1:],0]*1j
</pre>
</div>
</div>

<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>(0.003010774907922919, 0.380500212706883)
(0.00322203712556267, 0.37820316072720495)
(0.003124093734438364, 0.37575723113970955)
(0.0032067570456246405, 0.37314851535147125)
(0.2412569164556213, 0.8419023666523914)
</pre>
</div>
</div>

<div class="output_area"><div class="prompt"></div>


<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXAAAAECCAYAAADn84z1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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=
"
>
</div>

</div>

<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>[ 0.10977334  0.11159505  0.11363853  0.1116608   0.55333229]
Average rating estimate is: 3.8871836433290317
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we see that our computed means just about agree with the analytical ones at around $\frac{1}{9}$ for all the ratings except the last one which is $\frac{5}{9}$. 
We use this (or the analytical result) to estimate the true rating for the book to be at around 3.8 stars. Still a good rating, but not the 5 star average it gets otherwise.
We can temper our rating even more by giving more weight in our prior hyperparameters.
Using all tens instead of all ones and the estimate moves to just 3.2 stars.</p>
<p>Ideally, this is what Amazon should be doing when sorting by average rating to account for the uncertainty inherent in the items with only a few ratings.</p>
<p>Note here that if we use the MLE estimate for each of the probabilities (this does not include prior information), we would get $(0,0,0,0,1)$ and again the average rating would be 5.
A trick to get around this is to use a conservative estimate for each value from a simultaneous confidence interval for multinomial proportion.
There are <a href="http://rpackages.ianhowson.com/cran/CoinMinD/">several different methods</a> for computing these intervals and it can get pretty complicated.</p>
<p>Meanwhile, the analytical expressions for the Bayesian method can be ugly, but as we've seen, we don't need them.
We simply need to be able to simulate from the posterior to get accuarate estimates of the true proportions.</p>
<h2 id="Conclusion">Conclusion<a class="anchor-link" href="#Conclusion">&#182;</a></h2><ul>
<li>We saw that Bayesian inference can be a powerful and very general method for estimating parameters, while still being simple in principle.</li>
<li>The interpretation of Bayesian confidence intervals, as well as most other results, can be different even though the numbers end up the same.</li>
<li>We discussed likelihoods, choices of priors (briefly, with references) and posterior distributions.</li>
<li>We used MCMC, but didn't go into the details of how it works (maybe another time for that).</li>
<li>More data leads to less variation and less influence from the prior, so when there is a lot of data the Bayesian estimate can be very close to the frequentist one.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
